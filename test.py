import skimage
import matplotlib.pylab as plt
import cv2
import chardet
import json
import utils
import os
import numpy as np
import base64
import random
import config

image_path = 'elephant.jpg'


def load_image(self, image_id):
    """Load the specified image and return a [H,W,3] Numpy array.
    """
    # Load image
    image = skimage.io.imread(self.image_info[image_id]['path'])
    # If grayscale. Convert to RGB for consistency.
    if image.ndim != 3:
        image = skimage.color.gray2rgb(image)
    return image


def show_image(image):
    plt.imshow(image)
    plt.show()


def decode_base64():
    json_dir = '/Users/moubinhao/PycharmProjects/tensorflow_keras/4282682_0.json'
    image_data = json.load(open(json_dir))['imageData']
    print(image_data)

    img_b64decode = base64.b64decode(image_data)  # base64解码

    img_array = np.fromstring(img_b64decode, np.uint8)  # 转换np序列
    print(img_array.shape)
    # img = cv2.imdecode(img_array, cv2.COLOR_BGR2RGB)  # 转换Opencv格式
    #
    # cv2.imshow("img", img)
    # cv2.waitKey()


def return_tuple():
    x_train = np.random.random((2, 32, 32, 3))
    y_train = np.random.random((2, 1))
    return (x_train, y_train)


############################################################
#  Data Generator
############################################################

def load_image_gt(dataset, config, image_id, augment=False):
    """Load and return ground truth data for an image (image, mask, bounding boxes).

    augment: If true, apply random image augmentation. Currently, only
        horizontal flipping is offered.

    Returns:
    image: [height, width, 3]
    shape: the original shape of the image before resizing and cropping.
    class_ids: [instance_count] Integer class IDs

    """
    # Load image and mask
    image = dataset.load_image(image_id)
    class_ids = dataset.image_info[image_id]['class_id']
    shape = image.shape
    image, window, scale, padding = utils.resize_image(
        image,
        min_dim=config.IMAGE_MIN_DIM,
        max_dim=config.IMAGE_MAX_DIM,
        padding=config.IMAGE_PADDING)

    # Random horizontal flips.
    if augment:
        if random.randint(0, 1):
            image = np.fliplr(image)

    # Active classes
    # Different datasets have different classes, so track the
    # classes supported in the dataset of this image.
    active_class_ids = np.zeros([dataset.num_classes], dtype=np.int32)
    source_class_ids = dataset.source_class_ids[dataset.image_info[image_id]["source"]]
    active_class_ids[source_class_ids] = 1

    # Image meta data
    image_meta = compose_image_meta(image_id, shape, active_class_ids)

    return image, image_meta, class_ids


############################################################
#  Data Formatting
############################################################

def compose_image_meta(image_id, image_shape, active_class_ids):
    """Takes attributes of an image and puts them in one 1D array.

    image_id: An int ID of the image. Useful for debugging.
    image_shape: [height, width, channels]
    active_class_ids: List of class_ids available in the dataset from which
        the image came. Useful if training on images from multiple datasets
        where not all classes are present in all datasets.
    """
    meta = np.array(
        [image_id] +  # size=1
        list(image_shape) +  # size=3
        list(active_class_ids)  # size=num_classes
    )
    return meta


def mold_image(images):
    """Takes RGB images with 0-255 values and subtraces
    the mean pixel and converts it to float. Expects image
    colors in RGB order.
    """
    mean_pixel = np.array([123.7, 116.8, 103.9])
    return images.astype(np.float32) - mean_pixel


def data_generator(dataset, config, shuffle=True, augment=True, batch_size=1):
    """A generator that returns images and corresponding target class ids,
    bounding box deltas, and masks.

    dataset: The Dataset object to pick data from
    config: The model config object
    shuffle: If True, shuffles the samples before every epoch
    augment: If True, applies image augmentation to images (currently only
             horizontal flips are supported)
    random_rois: If > 0 then generate proposals to be used to train the
                 network classifier and mask heads. Useful if training
                 the Mask RCNN part without the RPN.
    batch_size: How many images to return in each call
    detection_targets: If True, generate detection targets (class IDs, bbox
        deltas, and masks). Typically for debugging or visualizations because
        in trainig detection targets are generated by DetectionTargetLayer.

    Returns a Python generator. Upon calling next() on it, the
    generator returns two lists, inputs and outputs. The containtes
    of the lists differs depending on the received arguments:
    inputs list:
    - images: [batch, H, W, C]
    - image_meta: [batch, size of image meta]
    - rpn_match: [batch, N] Integer (1=positive anchor, -1=negative, 0=neutral)
    - rpn_bbox: [batch, N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.
    - gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs
    - gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)]
    - gt_masks: [batch, height, width, MAX_GT_INSTANCES]. The height and width
                are those of the image unless use_mini_mask is True, in which
                case they are defined in MINI_MASK_SHAPE.

    outputs list: Usually empty in regular training. But if detection_targets
        is True then the outputs list contains target class_ids, bbox deltas,
        and masks.
    """
    b = 0  # batch item index
    image_index = -1
    image_ids = np.copy(dataset.image_ids)
    error_count = 0

    # Keras requires a generator to run indefinately.
    while True:
        try:
            # Increment index to pick next image. Shuffle if at the start of an epoch.
            # image_index = [0, 1, 2, 3, .....len(image_ids), 0, 1, 2,......]
            image_index = (image_index + 1) % len(image_ids)
            print("image_indes", image_index)
            if shuffle and image_index == 0:
                print("shuffling image_ids............")
                np.random.shuffle(image_ids)

            # Get GT bounding boxes and masks for image.
            image_id = image_ids[image_index]

            image, image_meta, gt_class_ids = load_image_gt(dataset, config, image_id, augment=augment)
            print("image[{:2}].shape = {}".format(image_id, image.shape))
            print("image_meta, gt_class_ids = {:10}{:10}".format(len(image_meta), len(gt_class_ids)))
            print("image_meta", image_meta)
            gt_class_ids = np.array(gt_class_ids, dtype=np.int32)
            print("gt_class_ids", gt_class_ids)

            # Init batch arrays
            if b == 0:
                batch_image_meta = np.zeros(
                    (batch_size,) + image_meta.shape, dtype=image_meta.dtype)
                batch_images = np.zeros(
                    (batch_size,) + image.shape, dtype=np.float32)
                batch_gt_class_ids = np.zeros(
                    (batch_size, config.MAX_GT_INSTANCES), dtype=np.int32)

            # Add to batch
            batch_image_meta[b] = image_meta

            batch_images[b] = mold_image(image.astype(np.float32))
            batch_gt_class_ids[b, :gt_class_ids.shape[0]] = gt_class_ids

            b += 1

            # Batch full?
            if b >= batch_size:
                inputs = [batch_images, batch_image_meta, batch_gt_class_ids]
                outputs = []
                yield inputs, outputs

                # start a new batch
                b = 0
        except (GeneratorExit, KeyboardInterrupt):
            raise
        except:
            # Log it and skip the image
            print("Error processing image {}".format(
                dataset.image_info[image_id]))
            error_count += 1
            if error_count > 5:
                raise


def gen_test():
    b = 0
    while True:
        b += 1
        # print("b=", b)
        if b >= 5:
            yield b


if __name__ == '__main__':
    file_dir = '/Users/moubinhao/Downloads/json'
    # with open(file_dir, 'rb+') as fp:
    #     content = fp.read()
    #     encoding = chardet.detect(content)['encoding']
    #     print(encoding)
    #     content = content.decode(encoding).encode(encoding='utf-8')
    #     print(chardet.detect(content)['encoding'])
    #     fp.seek(0)
    #     fp.write(content)

    # for index, file in enumerate(os.listdir(file_dir)):
    #     print(file)
    #     annotation = json.load(open(os.path.join(file_dir, file)))
    #     print(annotation['imagePath'])
    #     print(index)
    # decode_base64()
    # path = 'L_367'
    # try:
    #     img = plt.imread(path + '.jpg')
    #     plt.imshow(img)
    #     plt.show()
    # except:
    #     img = plt.imread(path + '.png')
    #     plt.imshow(img)
    #     plt.show()
    # (x_train, y_train) = return_tuple()


